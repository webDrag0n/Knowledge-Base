- #多智能体 #协同
- “眼力见”：从“任务驱动”转向“事件驱动”
  区别：任务由人类下达，而事件自然随机发生
  结果：增加适应性，更接近自主决策能力
  应用场景：康养机构，多机，需要主动
- 多个控制目标，多Agent，单人
	- 定义：人的行为改变控制目标状态时，人类行为可以视作一种环境的变化，通过中心化或去中心化的群体控制方法调整LLM prompt，使多Agent协同稳定目标状态，完成对目标状态的稳定控制
	- 例如：
		- 人在游戏中建房子时消耗不同数量的木头，石头和铁
		- Input：当前木头、石头和铁的总量，其他Agent的当前位置和行为
		- Action：自身目标位置姿态和到达目标后的动作
		- Goal：维持木头、石头和铁的总量不变
	- 例如：搬桌子问题
		- 3个机器人与1个人各搬一个角，初始状态平衡
		- Input：机器人知道桌子的位置姿态以及其他机器人的位置和施力方向
		- Action：机器人能够决策目标施力方向和自身目标位置
		- Goal：人朝某个方向移动后其他机器人需要保持桌子稳定并最终配合人放下桌子
	- 相关研究：
		- Zhang et al. (AAAI, 2024) "ProAgent: Building Proactive Cooperative Agents with Large Language Models"
			- 实验在Overcooked-AI环境中进行，结果显示ProAgent在与不同类型的AI队友协作时表现出显著优势，特别是在Zero-Shot协调场景中。此外，文中分析了ProAgent各模块的作用及其对性能的影响，证实了分析和信念对于提高决策准确性和效率的重要性，以及Verificator模块在提供反馈式推理中的关键作用。
		- Feng et al. (Arxiv, 2024) "Large Language Model-based Human-Agent Collaboration for Complex Task Solving"
		- Zhang et al. (Under review，2024) "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration"
		- Gupta et al. (CoRL，2023) “Multi-Agent Inverse Reinforcement Learning for Collaborative Task Optimization”
			- 提出了基于多智能体逆强化学习（Multi-Agent Inverse Reinforcement Learning, MAIRL）的协作任务学习框架，用于无人车和机器人的协同搬运任务。该方法通过示例学习优化了智能体在协作中的策略选择，使得系统能够在资源动态变化的环境中保持稳定
		- Zhang et al. (ICRA，2023) “Robust Cooperative Manipulation with Uncertainty Estimation for Multi-Robot Systems”
			- 在机器人协同搬运问题上引入了鲁棒控制方法，利用模糊逻辑和扰动估计技术，使得智能体在不确定性环境中仍能有效协调施力，从而维持物体的平衡。研究结果表明，该方法在执行协作搬运任务时可以有效降低资源消耗和姿态偏移
		- Jiang et al. (RA-L，2023) “Adaptive Control and Deep Reinforcement Learning for Dynamic Resource Management”
			- 提出了一种混合自适应控制和深度强化学习的框架，应用于机器人生产线中的资源管理。该方法能够在环境动态变化的情况下，实时优化资源分配和任务分工
		- Tang et al. “Delay-Compensated Distributed Consensus Algorithm for Multi-Agent Systems”, IEEE Transactions on Automatic Control, 2023.
		- Wang et al. (NeurIPS，2023) “LLM-Augmented Decision Making for Multi-Agent Collaboration”
			- 展示了LLM在多智能体协作任务中的应用。他们提出了一种混合框架，结合LLM的推理能力和强化学习的策略优化优势，应用于机器人协同搬运任务中。实验表明，LLM通过生成智能体的推理和协调策略，在不确定和部分可观察的环境中表现出更高的协作效率和稳定性
		- Zhang et al. (ICLR，2022) “Adaptive Cooperation with Large Language Model Reasoning”
			- 提出使用预训练的大语言模型作为多智能体系统的知识库和推理引擎。该模型用于实时生成每个智能体的控制策略和协作方案，特别是在遇到突发环境变化时表现出较高的自适应性。该方法被应用于无人机协同搬运和复杂路径规划任务中，显著减少了任务失败率并提高了整体任务完成效率
		- Liu et al. (ICRA，2023) “LLM-Guided Imitation Learning for Multi-Agent Collaborative Transport”
			- 展示了一项关于利用LLM和模仿学习解决机器人协同搬运的研究。LLM被用于推理和生成策略，从人类专家演示中学习并指导智能体的协作控制。实验结果显示，智能体在搬运任务中能够更好地调整施力方向和位置，以保持系统平衡
- ## 长期Roadmap
	- 基于[[Project Morpheus]]具备机器人物理仿真的任务
	  ![多智能体协同人类完成任务路线图.png](../assets/多智能体协同人类完成任务路线图_1729992866591_0.png)
- ## [[Autogame实习]]