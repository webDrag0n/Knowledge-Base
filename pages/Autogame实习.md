## 方案
	- ![截屏2024-11-05 18.24.07.png](../assets/截屏2024-11-05_18.24.07_1730802251128_0.png)
	- ### 任务定义
		- 目标：设计一个基于多智能体的AI系统，使智能体能与玩家协作，在战斗场景中执行长期探索收集任务。
		- 主要任务：
			- •	环境感知：开发AI系统对动态游戏环境的实时感知能力，涵盖敌人、资源、地形等多种要素。
			  •	长期决策：在无玩家指令下，智能体主动探索环境并收集资源，为后续任务提供支持。
		- 主要产出：数据集、论文
	- ### 主要创新
		- 目前已有类似研究：[ProAgent](Zhang et al. (AAAI, 2024) "ProAgent: Building Proactive Cooperative Agents with Large Language Models")
		- 预期中该方法可能存在待解决问题，也会是本工作的创新点：
			- 对材料数量控制不稳定
			- 可再生资源（如树木）依然需要玩家自己种植
		- 假设已知玩家箱子的数量与容量，各类物品数量应保持近似恒定比例，并分类整理，方便玩家取用。
		- 尝试使NPC学会在合适的位置种树：
			- 寻找适合种树不会影响到玩家的位置（玩家意图理解）
	- ### 数据收集
		- 任务：构建数据集以训练AI模型，实现环境感知和多模态决策。
		- •	环境数据：模拟或通过真实游戏数据获取不同场景的环境特征，包括资源位置、地形信息等。
		  •	玩家交互数据：收集玩家与智能体的协作数据，尤其是玩家在长期任务中的决策模式、行动路径等。
		  •	多模态数据：收集视觉、语言、地理和数值数据，方便智能体理解多模态信息。
		  •	数据预处理：对数据进行清理、标注、格式转换，并处理不同模态的时空对齐问题，一个动作序列应切分为多个不同决策。同类动作序列用来训练强化学习动作控制器，同任务目标的决策组合序列用来训练多模态大语言模型控制器。
	-
	-
	-
	-
	-
	-
	-
	-
	- ### 工程实现
		- 实现一个可以扮演单个任务的Agent，以如下架构为例
		- 1. Agent 实现
			- 编程语言：Python，因为它对机器学习库和API集成支持良好。
			- 框架：FastAPI 或 Flask，用于实现轻量级的Web服务器和API通信，以便实时交互。
		- 2. 事件驱动的视觉信息输入
			- 图像处理：使用 OpenCV 或 PIL 进行基本的图像处理。
			- 事件触发：采用 WebSocket 或发布/订阅模型（如 Redis Pub/Sub），实现实时事件驱动的更新，每5秒获取一次新环境数据。
			- 任务调度：使用 APScheduler 或 Celery 来处理周期性任务，如每5秒轮询一次环境数据。
			- 图像输入：Clip Image Embedding
		- 3. 记忆模块（Memory Module）
			- 库：使用 LangChain 管理长期记忆和对话历史。
			- 数据库：
				- 向量数据库：Pinecone、Weaviate 或 Qdrant，用于存储向量化的记忆数据，实现高效的相似性搜索。
				- 嵌入模型：使用 OpenAI：text-embedding-ada-002 嵌入模型，将记忆内容转化为向量格式。
		- 4. 规划模块（Planning Module）
			- 大语言模型（LLM）：Google的Gemini API，用于生成逐步的决策和解释。
			- 输出原因要求：在 LangChain 中进行提示词工程（prompt engineering），使模型在输出中包含决策原因和理由。
			- 决策记录：使用结构化日志（例如 JSON 格式，存储在 MongoDB 数据库中）记录每一步及其原因，便于分析和调试。
		- 5. 工具层（与游戏环境和数据库的API交互接口层）
			- API接口层：
				- HTTP请求：使用 requests 库进行 RESTful API 交互。
				- 数据库接口：使用 PyMongo 连接 MongoDB。
			- 工具框架：使用 LangChain 的工具模块，创建API交互封装器，使大语言模型能够无缝连接游戏环境和数据库。
			- API文档说明：使用自定义结构化文档，定义API端点，并为大模型提供清晰的API参数说明，确保模型理解API结构和所需参数。
		- ![Architecture diagram of an LLM-powered agent. The agent core is at the center with bi-directional arrow connecting user requests, memory module, planning module and tools. ](https://developer-blogs.nvidia.com/wp-content/uploads/2023/11/agent-components-625x379.png){:height 312, :width 495}
		  [*General components of an agent*](https://developer.nvidia.com/blog/introduction-to-llm-agents/)
	- ### 实验与测试
		- 仿真/游戏
		- 目标：验证智能体在不同任务场景中的表现，包括协作能力、环境感知、任务完成效率等。
		  •	长期任务测试：设计开放场景，让智能体在无玩家指令下独立探索，观察智能体是否能成功发现并收集有用资源。
		  •	人机协作体验：邀请测试玩家在复杂场景中与智能体协作完成任务，收集玩家的反馈数据，评估智能体的实际使用体验。
		  •	指标评估：通过以下指标评估模型效果：任务完成率、玩家满意度、资源收集数量、敌人击败数量、玩家负担降低率等。
	- ### 迭代优化
		- 目标：根据实验反馈和模型表现对系统进行改进。
		- •	模型微调：针对薄弱点（如环境感知不准确、战斗配合不顺畅）进行微调。
		  •	多模态数据增强：结合玩家反馈丰富数据集，以提高模型在不同任务中的适应性。
		  •	协作逻辑优化：提升智能体的协作智能，增强其自主性和响应速度，以提高玩家的交互体验。
	- ### 资源与时间规划
		- 阶段划分（半年）
			- 1.	前期准备（第1个月）：
				- 熟悉现有接口并测试API Token
				- 数据收集与标注
				- 定义环境感知和多模态任务特征。
			- 2.	模型开发与训练（第2-3.5个月）：多模态模型训练与评估，智能体短期和长期决策模型集成。
			  在Autogame开发环境以NPC合作采集消耗品材料为场景，复现[ProAgent](Zhang et al. (AAAI, 2024) "ProAgent: Building Proactive Cooperative Agents with Large Language Models")
				- 替换Observation Space
				- 替换Action Space
				- 测试加入玩家行为
			- 3.	实验测试与优化（第3.5-5个月）：系统实验验证、优化及迭代改进。
				- 单元测试
				- 集成测试NPC合作采集材料行为与其他行为的融合效果
				- 用户反馈收集
			- 4.	项目总结与验收（第6个月）：整体测试、总结调整，交付项目成果。
	- ### 所需资源
		- •	硬件资源：Claude大模型API，用于模型训练与验证。
		  •	开发工具：Python、PyTorch、游戏环境API。
		  •	标注资源：游戏环境及交互数据标注工具和人员。
	- ### 项目预期成果
		- •	论文发表和部分代码开源，申请专利。
		  •	核心智能体系统：具备多模态环境感知和决策能力的多智能体系统。
		  •	实验与用户反馈报告：总结不同场景下的实验结果和用户反馈。
		  •	应用案例和未来拓展建议：展示智能体协作在不同游戏场景的应用效果，以及对未来类似项目的改进建议。
	- 该项目的成果可广泛应用于游戏AI、虚拟助手等领域，同时积累的多模态协作数据可用于未来人机交互系统的优化。
	-