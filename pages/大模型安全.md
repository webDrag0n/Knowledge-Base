- #llm #安全
- ### **文献简介**
- #### [1] B. Wang等,
  2022  
  
  **链接**:
  [arXiv:2111.02840](https://arxiv.org/abs/2111.02840)  
  
  **发表平台/时间**: arXiv / 2022年1月10日  
  
  **主要特点**：基于对抗样本的多任务鲁棒性评测基准（覆盖文本蕴含、问答等任务）。  
  
  **贡献**：
- **LLM**：首次系统评估语言模型在对抗攻击下的鲁棒性，揭示模型对输入扰动的脆弱性。
- **LVLM**：为多模态模型对抗性评测提供方法论参考（需适配视觉-语言联合攻击）。
- #### [2] 《Beyond the imitation game benchmark》  
  Google BigBench
- **链接**：[arXiv论文](https://arxiv.org/abs/2206.04615) | [GitHub仓库](https://github.com/google/BIG-bench)
- **发表平台/时间**：TMLR / 2023年5月
  
  主要特点：构建一个覆盖广泛能力的大语言模型评测基准，突破传统评测的局限性（如任务单一、性能饱和问题）
  
  对LLM的贡献
  能力边界探索：首次系统性评估大模型在复杂任务（如国际象棋规则、电影推荐）中的潜力，揭示其隐藏技能15。
  
  社会偏见量化：通过任务设计（如性别、种族相关评测）推动模型公平性研究，提出上下文提示对偏见的调控作用515。
  
  评测基础设施：开源API代码，支持社区扩展新任务和模型评估15。
  
  对LVLM的潜在影响
  多模态评测参考：任务设计思路（如动态交互、多领域覆盖）可为视觉-语言联合评测提供范式15。
  
  社会偏见的跨模态风险：文本生成中的偏见检测方法可扩展至多模态场景（如文本-图像联合生成中的歧视性内容）5。
- #### [3] N. Nangia等,
  2020  
  
  **链接**:
  [arXiv:2010.00133](https://arxiv.org/abs/2010.00133)  
  
  **发表平台/时间**: arXiv / 2020年9月30日  
  
  **主要特点**：针对社会偏见的对抗性评测数据集（覆盖性别、种族等9类偏见）。 
  
  **贡献**：
- **LLM**：量化BERT等模型对刻板印象的敏感性，推动去偏方法研究。
- **LVLM**：启发多模态偏见检测（如文本-图像联合生成中的歧视性内容）。
- #### [4] Z. Guo等,
  2023  
  
  **链接**:
  [arXiv:2310.19736](https://arxiv.org/abs/2310.19736)  
  
  **发表平台/时间**: arXiv / 2023年11月25日  
  
  **主要特点**：系统性综述大模型评测方法（覆盖性能、伦理、安全等维度）。  
  
  **贡献**：
- **LLM/LVLM**：提出统一评估框架，强调伦理对齐需结合多模态场景（如视觉误导与文本偏见交叉风险）。
- #### [5] J. Ji等,
  2024  
  
  **链接**:
  [arXiv:2406.04428](https://arxiv.org/abs/2406.04428)  
  
  **发表平台/时间**: arXiv / 2024年6月6日  
  
  **主要特点**：首个跨文化道德评估基准（涵盖哲学理论驱动的伦理困境）。  
  
  **贡献**：
- **LLM**：量化模型道德判断与人类共识的偏差，揭示文化差异性影响。
- **LVLM**：为多模态道德决策（如自动驾驶伦理困境）提供评估范式。
- #### [6] S. Gehman等,
  2020  
  
  **链接**:
  [arXiv:2009.11462](https://arxiv.org/abs/2009.11462)  
  
  **发表平台/时间**: arXiv / 2020年9月25日  
  
  **主要特点**：基于真实语境的毒性生成评测数据集。  
  
  **贡献**：
- **LLM**：揭示模型在开放生成任务中产生有害内容的概率与提示词相关性。
- **LVLM**：警示多模态生成中视觉刺激可能加剧文本毒性（需跨模态毒性检测）。
- #### [7] M. Nadeem等,
  2020  
  
  **链接**:
  [arXiv:2004.09456](https://arxiv.org/abs/2004.09456)  
  
  **发表平台/时间**: arXiv / 2020年4月20日  
  
  **主要特点**：刻板印象偏向量化数据集（三元组选择任务）。  
  
  **贡献**：
- **LLM**：提出“刻板印象分数”指标，推动模型偏见缓解技术（如DebiasBERT）。
- **LVLM**：启发视觉-语言联合偏见的评估（如性别-职业关联的图像生成问题）。
- #### [8] A. Wang等,
  2020  
  
  **链接**:
  [arXiv:1905.00537](https://arxiv.org/abs/1905.00537)  
  
  **发表平台/时间**: arXiv / 2020年2月13日  
  
  **主要特点**：升级版语言理解评测基准（包含推理、指代消解等复杂任务）。  
  
  **贡献**：
- **LLM**：推动模型从基础语义理解向高阶逻辑一致性发展，间接促进伦理合理性。
- **LVLM**：为多模态推理任务（如视觉问答）提供复杂性评估参考。  
  
  
  
  ---
- ### **重要性排序**  
  
  基于对人类价值对齐与伦理评估的贡献度（从高到低）：  
  
  1. **[5] MoralBench (2024)**：首个系统化道德评估框架，直接量化LLM伦理偏差，具跨文化普适性。  
  
  2. **[3] CrowS-pairs (2020)**：社会偏见检测的开创性工作，奠定后续去偏研究基础。  
  
  3. **[6] RealToxicityPrompts (2020)**：揭示模型毒性生成风险，推动安全生成技术发展。  
  
  4. **[7] StereoSet (2020)**：量化刻板印象偏见的标准化方法，被广泛引用。  
  
  5. **[4] Evaluating LLMs Survey (2023)**：整合伦理评估维度，指导未来研究方向。 **（综述）** 
  
  6. **[1] Adversarial GLUE (2022)**：鲁棒性评测揭示模型价值判断的脆弱性。  
  
  7. **[8] SuperGLUE (2020)**：间接促进高阶伦理推理能力。  
  
  8. **[2] 《Beyond the imitation game》**：综述+Google BigBench数据集  
  
  ---
- ### **文献综述：人类价值一致性与伦理评估的关键挑战**
- #### 1. **评测基准的演进**
- **早期阶段**（2020）：以SuperGLUE（[8]）为代表的性能导向评测，缺乏伦理维度。
- **转折点**（2020）：CrowS-pairs（[3]）、RealToxicityPrompts（[6]）等聚焦社会偏见与毒性生成，推动伦理评测标准化。
- **成熟阶段**（2024）：MoralBench（[5]）构建多维度道德评估体系，结合哲学理论与实际场景。
- #### 2. **核心问题与解决方案**
- **社会偏见**：  
  
  -
  **检测**：CrowS-pairs（[3]）和StereoSet（[7]）通过对抗性语境或三元组选择量化偏见。  
  
  -
  **缓解**：提示工程、去偏微调（如使用反事实数据增强）。
- **毒性生成**：  
  
  -
  **评测**：RealToxicityPrompts（[6]）证明模型易受负面提示影响。  
  
  -
  **抑制**：基于规则过滤、RLHF（人类反馈强化学习）。
- **道德一致性**：  
  
  -
  **评估**：MoralBench（[5]）引入跨文化伦理困境，揭示模型决策与人类共识的偏差。  
  
  -
  **对齐**：道德知识注入（如伦理规则微调）、多专家投票机制。
- #### 3. **多模态扩展与挑战**
- **LVLM特有风险**：视觉-文本联合生成可能放大偏见（如种族刻板印象的图像生成）。
- **评估创新**：需开发跨模态伦理评测工具（如检测图文一致性中的道德冲突）。
- #### 4. **未来方向**
- **动态伦理适应**：构建可随社会价值观演变的评测框架（参考[4]）。
- **因果解释性**：定位伦理偏差的源头（训练数据、模型架构）。
- **跨文化泛化**：避免评估中的西方中心主义（MoralBench已初步尝试）。  
  
  
  
  ---
- ### **总结**  
  
  当前研究已从单一任务性能评测转向**多维度伦理对齐**，但仍面临三大挑战： 
  
  1. **评估标准的主观性**（道德判断因文化/群体而异）； 
  
  2. **多模态场景的复杂性**（视觉-语言联合伦理风险）； 
  
  3. **动态适应的滞后性**（模型难以实时响应价值观变迁）。  
  
  未来需融合技术优化（如动态伦理知识库）与跨学科协作（伦理学、社会学），推动LLM/LVLM向**安全可控、价值包容**的方向发展。